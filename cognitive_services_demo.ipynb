{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State of North Dakota Approachable AI - Cognitive Services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This demonstration acts as an introduction to Microsoft Cognitive Services. Unlike the custom models we have built thus far, these are highly advanced, specialized models that have been produced by Microsoft research engineers.\n",
    "\n",
    "These models solve specialized problems - but are state of the art at solving those problems. As a general piece of advice, if a cognitive services model can be used as part of your data science workflow, then it is ususually worth doing so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests # Important library that we use whenever making an API call to a website\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from PIL import Image # Python imaging library\n",
    "from io import BytesIO\n",
    "import os\n",
    "import sys\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract our secret key and the API endpoint from the system\n",
    "if 'COMPUTER_VISION_SUBSCRIPTION_KEY' in os.environ:\n",
    "    subscription_key = os.environ['COMPUTER_VISION_SUBSCRIPTION_KEY']\n",
    "else:\n",
    "    print(\"\\nSet the COMPUTER_VISION_SUBSCRIPTION_KEY environment variable.\\n**Restart your shell or IDE for changes to take effect.**\")\n",
    "    sys.exit()\n",
    "\n",
    "if 'COMPUTER_VISION_ENDPOINT' in os.environ:\n",
    "    endpoint = os.environ['COMPUTER_VISION_ENDPOINT']\n",
    "\n",
    "ocr_url = endpoint + \"vision/v2.0/ocr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set image_url to the URL of an image that you want to analyze.\n",
    "image_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/a/af/\" + \\\n",
    "    \"Atomist_quote_from_Democritus.png/338px-Atomist_quote_from_Democritus.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: A simple quote from wikimedia commons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the subscription key - we do this in a JSON header\n",
    "headers = {'Ocp-Apim-Subscription-Key': subscription_key}\n",
    "\n",
    "# Set the optional parameters that we want the model to interpret - unk is unknown\n",
    "params = {'language': 'unk', 'detectOrientation': 'true'}\n",
    "\n",
    "# Define the data - in this case it is coming from a URL, not from storage\n",
    "data = {'url': image_url}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send the JSON message to the service\n",
    "response = requests.post(ocr_url, headers=headers, params=params, json=data)\n",
    "response.raise_for_status()\n",
    "\n",
    "# Get the result of the model\n",
    "analysis = response.json()\n",
    "print(analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the word bounding boxes and text.\n",
    "\n",
    "def extract_info(analysis):\n",
    "    line_infos = [region[\"lines\"] for region in analysis[\"regions\"]]\n",
    "    word_infos = []\n",
    "    for line in line_infos:\n",
    "        for word_metadata in line:\n",
    "            for word_info in word_metadata[\"words\"]:\n",
    "                word_infos.append(word_info)\n",
    "    return word_infos\n",
    "\n",
    "word_infos = extract_info(analysis)\n",
    "word_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the image and overlay it with the extracted text.\n",
    "plt.figure(figsize=(5, 5))\n",
    "image = Image.open(BytesIO(requests.get(image_url).content))\n",
    "ax = plt.imshow(image, alpha=0.5)\n",
    "for word in word_infos:\n",
    "    bbox = [int(num) for num in word[\"boundingBox\"].split(\",\")]\n",
    "    text = word[\"text\"]\n",
    "    origin = (bbox[0], bbox[1])\n",
    "    patch = Rectangle(origin, bbox[2], bbox[3],\n",
    "                      fill=False, linewidth=2, color='y')\n",
    "    ax.axes.add_patch(patch)\n",
    "    plt.text(origin[0], origin[1], text, fontsize=20, weight=\"bold\", va=\"top\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Use a local image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the image path\n",
    "image_path = \"../data/demo-label.jpg\"\n",
    "\n",
    "# Read the image into a byte array\n",
    "image_data = open(image_path, \"rb\").read()\n",
    "\n",
    "# Set Content-Type to octet-stream - format needed for the model\n",
    "headers = {'Ocp-Apim-Subscription-Key': subscription_key, 'Content-Type': 'application/octet-stream'}\n",
    "\n",
    "# Set the optional parameters that we want the model to interpret - unk is unknown\n",
    "params = {'language': 'unk', 'detectOrientation': 'true'}\n",
    "\n",
    "# put the byte array into your post request\n",
    "response = requests.post(ocr_url, headers=headers, params=params, data = image_data)\n",
    "response.raise_for_status()\n",
    "\n",
    "# Get the result of the model\n",
    "analysis = response.json()\n",
    "analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the results from the response\n",
    "word_infos = extract_info(analysis)\n",
    "word_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the image and overlay it with the extracted text.\n",
    "plt.figure(figsize=(15, 15))\n",
    "image = Image.open(image_path)\n",
    "ax = plt.imshow(image, alpha=0.5)\n",
    "for word in word_infos:\n",
    "    bbox = [int(num) for num in word[\"boundingBox\"].split(\",\")]\n",
    "    text = word[\"text\"]\n",
    "    origin = (bbox[0], bbox[1])\n",
    "    patch = Rectangle(origin, bbox[2], bbox[3],\n",
    "                      fill=False, linewidth=2, color='y')\n",
    "    ax.axes.add_patch(patch)\n",
    "    plt.text(origin[0], origin[1], text, fontsize=20, weight=\"bold\", va=\"top\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Apply a translation and rotation to the image\n",
    "from scipy import ndimage\n",
    "image_angle = - analysis[\"textAngle\"]\n",
    "image_offset = (50, 130)\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "image = Image.open(image_path)\n",
    "rotated_image = ndimage.rotate(image, image_angle * 360 / 6.28)\n",
    "\n",
    "ax = plt.imshow(rotated_image, alpha=0.5)\n",
    "for word in word_infos:\n",
    "    bbox = [int(num) for num in word[\"boundingBox\"].split(\",\")]\n",
    "    text = word[\"text\"]\n",
    "    origin = (bbox[0] + image_offset[0], bbox[1] + image_offset[1])\n",
    "    patch = Rectangle(origin, bbox[2], bbox[3],\n",
    "                      fill=False, linewidth=2, color='y')\n",
    "    ax.axes.add_patch(patch)\n",
    "    plt.text(origin[0], origin[1], text, fontsize=20, weight=\"bold\", va=\"top\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
