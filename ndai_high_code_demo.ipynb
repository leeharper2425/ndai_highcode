{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# State of North Dakota: Approachable AI Hands On"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this demonstration, we will leverage several open-source python libraries to train, text and validate machine learning models\n",
    "\n",
    "We will introduce several commonly used, and well documented, data science packages:\n",
    "- Pandas - a popular data manipulation package\n",
    "- numpy - a package for accelerated mathematical operations on arrays\n",
    "- scikit-learn - allows for a range of machine learning models to be used with a common interface\n",
    "- matplotlib - pythons standard graph plotting package\n",
    "- seaborn - more advanced plotting, when installed alongside matplotlib improves the graphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put several standard import statements here - we will import specific scikit-learn packages later on as they are needed\n",
    "\n",
    "# Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "# Preprocessing components\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's put in some congiguration variables here\n",
    "data_path = \"../data/forestfires.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column definitions are as follows:\n",
    "\n",
    "1. X - x-axis spatial coordinate within the Montesinho park map: 1 to 9\n",
    "2. Y - y-axis spatial coordinate within the Montesinho park map: 2 to 9\n",
    "3. month - month of the year: 'jan' to 'dec'\n",
    "4. day - day of the week: 'mon' to 'sun'\n",
    "5. FFMC - FFMC index from the FWI system: 18.7 to 96.20\n",
    "6. DMC - DMC index from the FWI system: 1.1 to 291.3\n",
    "7. DC - DC index from the FWI system: 7.9 to 860.6\n",
    "8. ISI - ISI index from the FWI system: 0.0 to 56.10\n",
    "9. temp - temperature in Celsius degrees: 2.2 to 33.30\n",
    "10. RH - relative humidity in %: 15.0 to 100\n",
    "11. wind - wind speed in km/h: 0.40 to 9.40\n",
    "12. rain - outside rain in mm/m2 : 0.0 to 6.4\n",
    "13. area - the burned area of the forest (in ha): 0.00 to 1090.84\n",
    "(this output variable is very skewed towards 0.0, thus it may make\n",
    "sense to model with the logarithm transform)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset and do a few simple explorations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The head method shows the first few lines of the data, 5 by default\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's also see how many null values we have in our dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The describe method gives us summary statistics of all of the numeric columns in the dataframe\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see how correlated different columns might be with each other \n",
    "# note: a variable is always perfectly correlated with itself!\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And we can actually plot these relationships with seaborn\n",
    "sns.pairplot(df[[\"FFMC\", \"DMC\", \"DC\", \"ISI\", \"temp\", \"RH\", \"wind\", \"rain\", \"area\"]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we will perform some dataset preparation steps on the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any duplicate rows - the inplace = True will prevent python making a copy of the dataframe\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will remove the day column from the dataset\n",
    "df.drop(labels=\"day\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform indicator encoding on the month columns\n",
    "df = pd.get_dummies(df, columns=[\"month\"])\n",
    "\n",
    "# note - this operation automatically removes the original column to avoid downstream issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into a training set and a testing set\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we are going to perform dataset preparation steps that must be performed only on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deal with missing data in the DC column of the  training set by imputing with the mean\n",
    "\n",
    "# Instantiate an imputer\n",
    "imp = Imputer(missing_values=np.NaN, strategy=\"mean\")\n",
    "\n",
    "# Fit the imputer - this will ensure that both train and test data are fitted with the precise same mean\n",
    "imp.fit(df_train[[\"DC\"]])\n",
    "\n",
    "# Perform the imputation on the column - note you only need ravel if there is one column\n",
    "df_train[\"DC\"] = imp.transform(df_train[[\"DC\"]]).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deal with any other missing data by deleting the entire row \n",
    "df_train.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers\n",
    "# There are many ways of performing automatic outlier detection, here we will just do it with a threshold on FFMC\n",
    "\n",
    "def outlier_removal(dframe, threshold):\n",
    "    \"\"\"\n",
    "    Function to perform outlier removal on a pandas dataframe with the FFMC column\n",
    "    \"\"\"\n",
    "    # Create a boolean mask of all values that are  outside the expected range\n",
    "    rows_to_remove = dframe[\"FFMC\"] > threshold\n",
    "\n",
    "    # Remove the rows that the Boolean mask picked out\n",
    "    return dframe.drop(dframe[rows_to_remove].index)\n",
    "\n",
    "df_train = outlier_removal(df_train, 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the DC column using the z-transformation - called StandardScaler in SK-learn\n",
    "\n",
    "# Instantiate a standard scaler\n",
    "normalizer = StandardScaler()\n",
    "\n",
    "# Fit the standard scaler on the training data\n",
    "normalizer.fit(df_train[[\"DC\"]])\n",
    "\n",
    "# Perform the normalization - note you only need ravel if there is only one column\n",
    "df_train[\"DC\"] = normalizer.transform(df_train[[\"DC\"]]).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Engineer an extra column - this extra column is an indicator whether it rained or not\n",
    "\n",
    "def add_did_it_rain(dframe):\n",
    "    \"\"\"\n",
    "    Add an extra Boolean indicator column indicating whetherit rained or not that day.\n",
    "    \n",
    "    Note that the condition returns the negative condition, so we set the \"other\" to the positive condition\n",
    "    \"\"\"\n",
    "    dframe[\"did_it_rain\"] = dframe[\"rain\"].where(dframe[\"rain\"] == 0.0, other = 1)\n",
    "    return dframe\n",
    "\n",
    "df_train = add_did_it_rain(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's build a linear regession model on the training set, and then run it on the test set\n",
    "\n",
    "This method will serve well to illustrate how to build a single machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training feature matrix and target vector\n",
    "X_train = df_train.drop(\"area\", axis=1)\n",
    "y_train = df_train[\"area\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a linear regression model - use n_jobs to parallelize the calculations\n",
    "model = LinearRegression(n_jobs=-1, fit_intercept=True)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Print the beta-parameters and the y-intercept\n",
    "print(\"Model parameters: {}\".format(model.coef_))\n",
    "print(\"Model y-intercept: {:.2f}\".format(model.intercept_))\n",
    "print(\"Training R^2 parameter: {:.4f}\".format(model.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now need to prepare the test set using the exact same method as we used to prepare the training set\n",
    "\n",
    "# Use our previouly created imputer to fill in the NaNs with the average from the training set\n",
    "\n",
    "# Perform the imputation on the column - note you only need ravel if there is one column\n",
    "df_test[\"DC\"] = imp.transform(df_test[[\"DC\"]]).ravel()\n",
    "\n",
    "# Deal with any other missing data by deleting the entire row \n",
    "df_test.dropna(inplace=True)\n",
    "\n",
    "# Remove outliers\n",
    "df_test = outlier_removal(df_test, 120)\n",
    "\n",
    "# Perform the normalization using the previously defined standard scaler\n",
    "df_test[\"DC\"] = normalizer.transform(df_test[[\"DC\"]]).ravel()\n",
    "\n",
    "# Add the \"did it rain\" feature\n",
    "df_test = add_did_it_rain(df_test)\n",
    "\n",
    "# extract the test features and the test target\n",
    "X_test = df_test.drop(\"area\", axis=1)\n",
    "y_test = df_test[\"area\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model to make some predictions\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score the model on the test set\n",
    "score = model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion - this model is exceptionally bad - it is worse than just predicting the same value for all elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's now look at a Random Forest Regression\n",
    "\n",
    "Note: that these models have hyperparameters, so we are going to have to use cross-validation to optimize our model\n",
    "\n",
    "Note: we should perform the dataset manipulation in the cross-validation loop. However, since we have a separate test\n",
    "dataset, and we are only using this to optimize our model this is unlikely to matter too much in practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a Random Forest Regression model \n",
    "rf_model = RandomForestRegressor(n_estimators=100, max_depth=10)\n",
    "\n",
    "# Run cross-validation on this model using the training set\n",
    "# We feed in the model, our training set and the number of folds we want to use\n",
    "scores = cross_validate(rf_model, X_train, y_train, cv=5, scoring=[\"r2\", \"neg_mean_squared_error\"])\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run through a bunch of hyperparameters to see which the best ones are\n",
    "\n",
    "This is called a **gridsearch**\n",
    "\n",
    "There is a module in SKLearn that can do this for us automatically, but let's just do it manually for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a grid of hyperparameters to choose from\n",
    "tree_grid = [100, 200, 300]\n",
    "depth_grid = [1, 5, 10, 20]\n",
    "\n",
    "# Initialize a dictionary data structure to store the results\n",
    "results = {}\n",
    "\n",
    "for n_trees in tree_grid:\n",
    "    for depth in depth_grid:\n",
    "        rf_model = RandomForestRegressor(n_estimators=n_trees, max_depth=depth)\n",
    "        result = cross_validate(rf_model, X_train, y_train, cv=5, scoring=[\"r2\", \"neg_mean_squared_error\"])\n",
    "        # Compute the average results\n",
    "        r2 = np.mean(result[\"test_r2\"])\n",
    "        RMSE = np.sqrt(-1 * np.mean(result[\"test_neg_mean_squared_error\"]))\n",
    "        \n",
    "        # update the dictionary - the key will be a tuple of hyperparameters, the value a tuple of metrics\n",
    "        results[(n_trees, depth)] = (r2, RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for key, value in results.items():\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peform the final validation - notice a model can be trained and tested in 3 lines of code, if desired\n",
    "rf_final_model = RandomForestRegressor(n_estimators=100, max_depth=1)\n",
    "rf_final_model.fit(X_train, y_train)\n",
    "predictions = rf_final_model.predict(X_test)\n",
    "score = rf_final_model.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
